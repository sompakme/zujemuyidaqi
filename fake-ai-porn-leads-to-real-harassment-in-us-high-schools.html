<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=description content="When Ellis, a 14-year-old from Texas, woke up one October morning with several missed calls and texts, they were all about the same thing: nude images of her circulating on social media. That she had not actually taken the pictures didn't make a difference, as artificial intelligence makes so-called &amp;quot;deepfakes&amp;quot; more and more realistic."><meta name=author content="Jenniffer Sheldon"><meta name=generator content="Hugo 0.98.0"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/base16/css/style.css type=text/css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type=text/css><link rel=alternate href=./index.xml type=application/rss+xml title=ZenVlog><title>Fake AI porn leads to real harassment in US high schools - ZenVlog</title></head><body><header><div class="container clearfix"><a class=path href=./index.html>[ZenVlog]</a>
<span class=caret># _</span><div class=right></div></div></header><div class=container><main role=main class=article><article class=single itemscope itemtype=http://schema.org/BlogPosting><div class=meta><span class=key>published on</span>
<span class=val><time itemprop=datePublished datetime=2024-07-29>July 29, 2024</time></span>
<span class=key>in</span>
<span class=val><a href=./categories/blog>blog</a></span></div><h1 class=headline itemprop=headline>Fake AI porn leads to real harassment in US high schools</h1><section class=body itemprop=articleBody><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/43ccf8ed0714db99.jpg><p class=align-left>When Ellis, a 14-year-old from Texas, woke up one October morning with several missed calls and texts, they were all about the same thing: nude images of her circulating on social media.</p><p class=align-left>That she had not actually taken the pictures didn't make a difference, as artificial intelligence makes so-called "deepfakes" more and more realistic.</p><p class=align-left>The images of Ellis and a friend, also a victim, were lifted from Instagram, their faces then placed on naked bodies of other people. Other students -- all girls -- were also targeted, with the composite photos shared with other classmates on Snapchat.</p><p class=align-left>"It looked real, like the bodies looked like real bodies," she told AFP. "And I remember being really, really scared... I've never done anything of that sort."</p><p class=align-left>As AI has boomed, so has deepfake pornography, with hyperrealistic images and videos created with minimal effort and money -- leading to scandals and harassment at multiple high schools in the United States as administrators struggle to respond amid a lack of federal legislation banning the practice.</p><a class=c-article-read-also__image-wrapper href=#><img sizes=256px style=margin:auto;display:block;text-align:center src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/cd01f8fb40e50197.png></a><a class=c-article-read-also__headline href=# readability=29><p class=c-article-read-also__caption>Read also</p><p class=c-article-read-also__headline-wrapper><span class=c-article-read-also__headline-hover-inner>2023 in review: "Dey Play", "Let the poor breath", and 3 other Nigerian slangs that ruled the year</span></p></a><p class=align-left>"The girls just cried, and cried forever. They were very ashamed," said Anna Berry McAdams, Ellis' mother, who was shocked at how realistic the images looked. "They didn't want to go to school."</p><h2>'A smartphone and a few dollars'</h2><p class=align-left>Though it's hard to quantify how widespread deepfakes are becoming, Ellis' school outside of Dallas isn't alone.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/cd01f8fb40e50197.png><p class=align-left>At the end of the month, another fake nudes scandal erupted at a high school in the northeastern state of New Jersey.</p><p class=align-left>"It will happen more and more often," said Dorota Mani, the mother of one of the victims there, also 14.</p><p class=align-left>She added that there is no way to know if pornographic deepfakes might be floating around on the internet without one's knowledge, and that investigations often only arise when victims speak out.</p><a class=c-article-read-also__image-wrapper href=#><img sizes=256px style=margin:auto;display:block;text-align:center src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/3e491a1522848d81.jpg></a><a class=c-article-read-also__headline href=# readability=27><p class=c-article-read-also__caption>Read also</p><p class=c-article-read-also__headline-wrapper><span class=c-article-read-also__headline-hover-inner>News anchors targeted by deepfake scammers on Facebook</span></p></a><p class=align-left>"So many victims don't even know there are pictures, and they will not be able to protect themselves -- because they don't know from what."</p><p class=align-left>At the same time, experts say, the law has been slow to catch up with technology, even as cruder versions of fake pornography, often focused on celebrities, have existed for years.</p><p class=align-left>Now, though, anyone who has posted something as innocent as a LinkedIn headshot <a href=#>can</a> be a victim.</p><p class=align-left>"Anybody who was working in this space knew, or should have known, that it was going to be used in this way," Hany Farid, a professor of computer science at the University of California, Berkeley, told AFP.</p><p class=align-left>Last month, President <a href=# rel=noopener>Joe Biden</a> signed an executive order on AI, calling on the government to create guardrails "against producing child sexual abuse material and against producing non-consensual intimate imagery of real individuals."</p><p class=align-left>And if it has proved difficult in many cases to track down the individual creators of certain images, that shouldn't stop the AI companies behind them or social media platforms where the photos are shared from being held accountable, says Farid.</p><a class=c-article-read-also__image-wrapper href=#><img sizes=256px style=margin:auto;display:block;text-align:center src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/9e808034dd5674ec.jpg></a><a class=c-article-read-also__headline href=# readability=27><p class=c-article-read-also__caption>Read also</p><p class=c-article-read-also__headline-wrapper><span class=c-article-read-also__headline-hover-inner>Social media titans caught in Gaza storm over content</span></p></a><p class=align-left>But no national legislation exists restricting deep fake porn, and only a handful of states have passed laws regulating it.</p><p class=align-left>"Although your face has been superimposed on a body, the body is not really yours," said Renee Cummings, an AI ethicist.</p><p class=align-left>That can create a "contradiction in the law," the University of Virginia professor told AFP, since it can be argued that existing laws prohibiting distributing sexual photos of someone without their consent don't apply to deepfakes.</p><p class=align-left>And while "anyone with a smartphone and a few dollars" can make the images, using widely available software, many of the victims -- who are primarily young women and girls -- "are afraid to go public."</p><p class=align-left>Deepfake porn "can destroy someone's life," said Cummings, citing victims who have suffered anxiety, depression and Post-Traumatic Stress Disorder.</p><h2>Fake photos, real trauma</h2><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/1378f62f3985e882.jpg><p class=align-left>In Texas, Ellis was interviewed by the police and school officials. But the <a href=#>education</a> and judicial systems appear to be caught flat-footed.</p><a class=c-article-read-also__image-wrapper href=#><img sizes=256px style=margin:auto;display:block;text-align:center src=https://cdn.statically.io/img/netstorage-legit.akamaized.net/images/6047e70da68510f8.png></a><a class=c-article-read-also__headline href=# readability=27><p class=c-article-read-also__caption>Read also</p><p class=c-article-read-also__headline-wrapper><span class=c-article-read-also__headline-hover-inner>"So good that people steal it": Nigerian artist cries out in pain as pirates ravage her artworks</span></p></a><p class=align-left>"It just crushes me that we don't have things in place to say, 'Yes, that is child porn,'" said Berry McAdams, her mother.</p><p class=align-left>The classmate behind Ellis' photos was temporarily suspended, but Ellis -- who previously described herself as social and outgoing -- remains "constantly filled with anxiety," and has asked to <a href=#>transfer</a> schools.</p><p class=align-left>"I don't know how many people could have saved the photos and sent them along. I don't know how many photos he made," she says.</p><p class=align-left>"So many people could have gotten them."</p><p class=align-left>Her mother, meanwhile, worries about if -- or, given the longevity of the internet, when -- the photos might resurface.</p><p class=align-left>"This could affect them for the rest of their lives," she says.</p><p>Source: AFP</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7rbHGoqtnppdkr7a%2FyKecrKtdmrCwus6msGislZi1r7vLqJ6yZ2Fqg3WFkG5kn5mbmnqitYyppqumXaGyorDSZqmemZxitaK%2BwKyqpp2eqXqptcahZKybmKS8rb%2BO</p></section></article></main></div><footer><div class=container><span class=copyright>&copy; 2024 ZenVlog - <a rel=license href=http://creativecommons.org/licenses/by/4.0/>CC BY 4.0</a></span></div></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>